# 動画音声合成のベースライン

ここがベースとなる基本的なブランチになります。
以下、実行までの手順です！


## リポジトリのクローン
ホームディレクトリでクローンをお願いします（ターミナルでcdと打った時の状態）。

`git clone https://github.com/Fuji1226/lip2sp_pytorch.git`


## Dockerのインストール
Dockerを使って仮想環境を立てる必要があるので、まずはそれのインストールをお願いします。

おそらく以下のURLからやっていただくと良いと思います。もしダメだった場合、「Docker mac」とかで検索してみてください。

https://docs.docker.com/desktop/install/mac-install/


## Dockerイメージのビルド
まずは、リモートのbaselineブランチをもとにローカルブランチを作成してください。

`git checkout -b ローカルブランチ名 origin/baseline`

次に、DockerfileをもとにDockerイメージをビルドします。

`docker build -t lip2sp_pytorch .`

上記のコマンドの場合、ビルドされるイメージの名前は`-t`の次にある`lip2sp_pytorch`です。
ここは自由につけていただいて構いませんが、わかりやすい方が良いかなと思い、とりあえずGitHubのリポジトリ名をつけています。

ビルドには結構時間がかかると思います。

終わったら、`docker image ls`と打ってみて、イメージができていることを確認してください。


## Dockerコンテナの起動
ビルドされたイメージをもとに、作業するためのコンテナを起動します。

`docker run OPTION IMAGEID`

`IMAGEID`は、`docker image ls`と打った時に表示されるIMAGE IDのことです。
ここをコピペしてください。

`OPTION`は、コンテナ実行時のオプションになります。
調べていただくと色々あるのですが、とりあえず以下のオプションを設定しておけば事足りるかと思います。

* `--rm`：これを書くことで、作業終了時にコンテナを停止した際、コンテナが自動で削除されます。もし同じコンテナを繰り返し使いたいというこだわりがあれば、こちらは書かないで大丈夫です。自分はそういったこだわりがないので、毎回消して新しいコンテナを作ってます。同じコンテナを使いたい場合は、`docker run`だと毎回コンテナを作ってしまうので、それ用のコマンドが別にあると思います。自分は詳しくないので、興味があれば調べてみてください。
* `—-mount type=bind,src=マウントしたい対象までのパス,dst=マウント先のパス`：これを書くことで、コンテナにローカルのファイルをバインドマウントすることができます。バインドマウントすることで、コンテナの中で作業した結果がローカルに反映されます。コマンド内の`-type`によってマウントの仕方が変わるので、コンテナ内で作業した結果をローカルに反映したくない場合などあれば、調べてみてください。自分はあまりそういった場面がないので、基本バインドマウントしてます。
* `-it`：これにより、コンテナ起動時にシェルが起動してくれます。

こういったオプションを指定し、例えば下記のような感じで実行します。

`docker run --rm -it --mount type=bind,src=/Users/abc/lip2sp_pytorch,dst=/root/lip2sp_pytorch --mount type=bind,src=/Users/abc/dataset,dst=/root/dataset --mount type=bind,src=/Users/abc/.ssh,dst=/root/.ssh IMAGEID`

この例では`Users/abc`がローカルのホームディレクトリにあたります。

`lip2sp_pytorch`ディレクトリ、`dataset`ディレクトリ、`.ssh`ディレクトリをコンテナにバインドマウントしています。

これにより、コンテナ内で`lip2sp_pytorch`のコードと`dataset`のデータを利用して、実行できるようになります。
`.ssh`については、`lip2sp_pytorch`においてitoからデータをダウンロードするコードを実行したいのですが、その際に必要になるのでマウントしています。

`dst`で指定したコンテナ内のパスにマウントされるので、この例の場合は`/root/lip2sp_pytorch`、`/root/dataset`、`/root/.ssh`にマウントされます。
コードの都合上、ホームディレクトリに置いていただくことを前提として書いています。
コンテナ内におけるホームディレクトリは`/root`になるので、そこをマウント先のパスとして指定しています。

他にもマウントしたいものがあれば、同じ要領で追記していただければ良いと思います。


## VSCodeで起動したDockerコンテナに接続
起動したコンテナ内で作業するため、VSCodeでコンテナに接続します。

VSCodeに「Dev Containers」という拡張機能があり、それを使って接続する感じです。

「vscode dockerコンテナ 接続」とかで検索していただくとありますので、それに従ってやってみてください。

例えば以下のサイトなどです。

https://tech.nri-net.com/entry/using_docker_containers_with_vscode


## ITOからデータのダウンロード
まず、itoの日高さんに作っていただいたスクリプトを停止します。
scrapboxの手順に従った場合、itoでgpuの確認などができるシェルスクリプトが自動的に実行されると思います。
しかし、自動で実行されるとダウンロードの時にバグるので、一旦実行されないように設定を変えます。

`vim ~/.bashrc`とターミナルで打つことでvimエディタで`.bashrc`ファイルをいじれる状態になります。
おそらく`source ~/ito_shared/main.sh minami`という行があると思うので、`# source ~/ito_shared/main.sh minami`のように頭に`#`をつけて、コメントアウトしてください。

これにより、シェルが立ち上がった時に自動で実行されなくなります。

次に、`/data_process/download_from_ito.py`を実行します。
変更しなければいけない箇所があるので、コードを確認してください。

ダウンロードが終わったら、コメントアウトしたところを戻しておきましょう。


## コードの実行
学習用スクリプトが`train_nar.py`、合成用スクリプトが`generate_nar.py`になります。

### `train_nar.py`の実行
1. `wandb.login(key="")`というところがあるので、この`key`を自分のアカウントのものに変更。
2. `python train_nar.py`で実行。
3. `/check_point`というディレクトリが作成され、`1.ckpt`のようなファイルが保存されることを確認してください。

### `generate_nar.py`の実行
1. `/check_point`というディレクトリには、学習時のチェックポイント（モデルパラメータなどを保存したもの）保存されています。そこから、ディレクトリ内の一番最後のチェックポイントのパスをコピーし、`/conf/test/nar.yaml`の`model_path`をそのパスに変更してください。
2. `python generate_nar.py`で実行。
3. `/result`というディレクトリに、チェックポイントディレクトリの日付と同じ日付のディレクトリが作成されると思います。ここに、そのチェックポイントを使って合成した結果が保存されます。

どこにどのような内容のコードがあるか、以下に記載しておきます。

* /conf：hydraによるハイパーパラメータの管理を行なっています。データのパスや前処理のパラメータ、モデルのパラメータなどは全てここで設定します。

* /data_process：データの前処理関連をまとめています。動画処理、音声処理、npzファイルとしての保存など。

* /dataset：学習やテストにおいてDataLoaderの作成に必要となる、Dataset、Transform、collate_fnを書いています。

* /model：モデルの構造を書いたファイルをまとめています。モデルのパーツを分割して書き、`model_nar.py`でそれらをまとめて最終的なモデルとしています。

* calc_accuracy.py：`generate_nar.py`において、合成音声に対しての客観評価指標の算出に用います。

* data_check.py：`generate_nar.py`において、合成したサンプルの保存に用います。

* loss.py：`train_nar.py`において、損失関数として用います。

* utils.py：`train_nar.py`や`generate_nar.py`などで使われる色々な関数をまとめています。例えば、データのパスの取得、DataLoaderの構築、学習時における損失・合成されたサンプルの記録、合成時における事前学習済みモデルの読み込みなどです。研究を進めていく中で学習や合成のスクリプトは複数になることが予想されますが、いつでも共通して使うような汎用性高めの関数をまとめている感じです。


## Dockerコンテナの停止
ターミナルで`exit`と打つことで、コンテナを停止して仮想環境から抜けます。


## ITOでの実行に向けて
ローカルで作ったものはITOで使いたいと思うので、一旦リモートリポジトリにプッシュしてください。

それからITOにアクセスし、今度はITOでリモートリポジトリからプルしましょう。

あとはITOにシェルスクリプトでジョブを投げてみてください。ITOでやってみるとバグったりもするので、その辺はITO上で頑張ってください…！