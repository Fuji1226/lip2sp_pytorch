
  - 現在の研究室のGPU使用状況は，
    「onsei_check_gpus」というコマンドで確認できます。
  - 自分が確保したいGPUの枚数は，
    「onsei_register_desired_gpus」というコマンドで登録できます。
    - GPUを当分使う予定がない場合の例（期限を9999年12月31日に設定）
      onsei_register_desired_gpus 0 9999/12/31
    - 8枚確保したい場合の例（期限を2022年10月15日に設定し，コメントを付ける）
      onsei_register_desired_gpus 8 2022/10/15 '研究締切のためすみません'
    - 最低2枚確保し，研究室全体で余ったGPUも使いたい場合の例
      onsei_register_desired_gpus 2 2022/10/15 '余剰GPUを使わせていただきます'

USER      RUNNING DESIRED     TO DATE  COMMENT
============================================================================
hidaka          0       0  9999/12/31  自動コメント：2022/09/30に期限切れ
minami          0       4  2022/10/31  余剰GPUを使わせていただきます
takehisa        0       2  2022/10/31  (仮)
fujita          7       5  2022/10/31  使います
============================================================================
Remaining       9

wandb: Currently logged in as: naoaki. Use `wandb login --relogin` to force relogin
/home/usr1/q70261a/.pyenv/versions/3.8.10/lib/python3.8/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
device = cuda
model path
/home/usr1/q70261a/lip2sp_pytorch_all/lip2sp_920_re/check_point/default/lip/2022:10:08_00-31-02_build_prenet/mspec80_160.ckpt
Error executing job with overrides: ['train.debug=False', 'tag=build_prenet', 'model_path=/home/usr1/q70261a/lip2sp_pytorch_all/lip2sp_920_re/check_point/default/lip/2022:10:08_00-31-02_build_prenet/mspec80_160.ckpt']
Traceback (most recent call last):
  File "generate.py", line 267, in main
    model.load_state_dict(torch.load(str(model_path))['model'])
  File "/home/usr1/q70261a/.pyenv/versions/3.8.10/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1497, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for Lip2SP:
	Missing key(s) in state_dict: "decoder.prenet.conv1.weight", "decoder.prenet.conv1.bias", "decoder.prenet.conv2.weight", "decoder.prenet.conv2.bias", "decoder.prenet.conv3.weight", "decoder.prenet.conv3.bias". 
	Unexpected key(s) in state_dict: "decoder.prenet.fc.0.weight", "decoder.prenet.fc.0.bias", "decoder.prenet.fc.3.weight", "decoder.prenet.fc.3.bias", "decoder.prenet.fc.6.weight", "decoder.prenet.fc.6.bias". 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "generate.py", line 269, in main
    model.load_state_dict(torch.load(str(model_path), map_location=torch.device('cpu'))['model'])
  File "/home/usr1/q70261a/.pyenv/versions/3.8.10/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1497, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for Lip2SP:
	Missing key(s) in state_dict: "decoder.prenet.conv1.weight", "decoder.prenet.conv1.bias", "decoder.prenet.conv2.weight", "decoder.prenet.conv2.bias", "decoder.prenet.conv3.weight", "decoder.prenet.conv3.bias". 
	Unexpected key(s) in state_dict: "decoder.prenet.fc.0.weight", "decoder.prenet.fc.0.bias", "decoder.prenet.fc.3.weight", "decoder.prenet.fc.3.bias", "decoder.prenet.fc.6.weight", "decoder.prenet.fc.6.bias". 

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
