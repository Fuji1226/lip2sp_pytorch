---

name: master

#################################
# data_info
#################################
# video parameter
fps: 25

# audio parameter
sampling_rate: 16000
n_fft: 512
hop_length: 160
hop_length_sec: 0.01
win_length: 400
win_length_sec: 0.025
f_min: 0
f_max: 8000
n_mel_channels: 80
mcep_order: 25
avhubert_nfilt: 26
avhubert_preemph: 0.97
feature_normalize: 'all_stat'

# input grayscale（グレースケールかRGBか）
gray: True

# input first and second derivative.（動的特徴量を使うかどうか）
delta: False

# frame period
frame_period: 10

# phoneme length
phoneme_length: 30

# reduction factor
reduction_factor: 4

# "world" or "mspec"（音響特徴量の選択）
feature_type: "mspec"

# 非周期性指標の圧縮方法
comp_mode: 'default'

# 学習に使用する口唇動画の秒数
input_lip_sec: 10

# 動画
mov_preprocess_method: "bbox_crop"
align_desired_left_eye: 0.35
align_desired_face_size: 128
margin: 0.15
imsize: 96
imsize_cropped: 88
is_large: True
avhubert_lip_mean: 0.421 
avhubert_lip_std: 0.165

# griffin-limで合成するときに人為的に補正
sharp: False

# mulaw量子化の学習中においてパディングを無視するためのインデックス
mulaw_ignore_idx: -1

#################################
# model_info
#################################
# in_channels
in_channels: 1
use_lip_and_face: False

# ResNet3D parameter
res_inner_channels: 32
which_res: "avhubert"

# speaker embedding
spk_emb_dim: 256

# glu parameter
glu_layers: 6    # 4 or 6
glu_kernel_size: 5   # 5 or 9
glu_inner_channels: 256

# transformer parameter
trans_enc_n_layers: 4    # 1, 2 or 4
trans_enc_n_head: 4    # 2 or 4
trans_dec_n_layers: 4
trans_dec_n_head: 4

# conformer
conf_n_layers: 6
conf_n_head: 4
conf_feed_forward_expansion_factor: 8

# rnn parameter
rnn_n_layers: 2
rnn_which_norm: "ln"

# transposed convolution parameter
tc_n_layers: 3
tc_kernel_size: 5

# 使用するencoder
which_encoder: "gru"

# 使用するdecoder
which_decoder: "restc"

# audio encoder
ae_emb_dim: 16
vae_emb_dim: 64
vq_emb_dim: 256
vq_num_emb: 64
norm_type_audio: "in"
content_d_model: 256
content_n_attn_layer: 1
content_n_head: 4
which_spk_enc: "rnn"
audio_enc_hidden_channels: 128
audio_enc_conv_dropout: 0.1
audio_enc_which_encoder: ''
audio_enc_rnn_n_layers: 2
audio_enc_rnn_dropout: 0.1
audio_enc_conf_n_Layers: 6
audio_enc_conf_n_head: 4
audio_enc_conf_feed_forward_expansion_factor: 8

# audio decoder
audio_dec_hidden_channels: 256
audio_dec_each_gru_n_layers: 1
audio_dec_n_gru_layers: 4
audio_dec_which_decoder: 'gru'
audio_dec_rnn_n_layers: 2
audio_dec_rnn_dropout: 0.1
audio_dec_conf_n_layers: 6
audio_dec_conf_n_head: 4
audio_dec_conf_feedforward_expansion_factor: 8
audio_dec_conv_dropout: 0.1

# domain classifier
which_domain_classifier: 'linear'
domain_classifier_hidden_channels: 128
domain_classifier_n_layers: 3
domain_classifier_n_conv_layers: 2
domain_classifier_conv_dropout: 0
domain_classifier_rnn_n_layers: 2
domain_classifier_rnn_dropout: 0

# feature converter
which_feature_converter: 'linear'
converter_hidden_channels: 128
converter_n_layers: 3
converter_dropout: 0
converter_n_conv_layers: 2
converter_conv_dropout: 0
converter_rnn_n_layers: 2
converter_rnn_dropout: 0

# mutual information
mi_hidden_channels: 256

# discriminator
which_d: "jcu"

# out_channels
out_channels: 80

# Prenet & Postnet parameter
pre_in_channels: 160  # 音響特徴量から計算します
pre_inner_channels: 32
post_inner_channels: 256
post_n_layers: 5   # 5
post_kernel_size: 5  # 5

# enhancer parameter
which_enhancer: "2D"   # 2D or 1D
lstm_layers: 1
bidirectional: True

# parallel wave gan
pwg_in_channels: 1
pwg_out_channels: 1
pwg_gen_inner_channels: 64
pwg_cond_channels: 80
pwg_upsample_scales: [10, 4, 2, 2]
pwg_gen_n_layers: 30
pwg_gen_n_stacks: 3
pwg_disc_inner_channels: 64
pwg_disc_n_layers: 10
pwg_disc_n_layers_wavenet: 30
pwg_disc_n_stacks: 3
pwg_kernel_size: 3
pwg_gen_dropout: 0.1
pwg_disc_dropout: 0
pwg_use_weight_norm: False
pwg_which_disc: "normal"

# tacotron2
n_vocab: 52
taco_dec_n_layers: 2
taco_dec_hidden_channels: 512
taco_dec_conv_channels: 32
taco_dec_conv_kernel_size: 75   # 動画なので31だと短い？
taco_use_attention: False
taco_enc_hidden_channels: 512
taco_enc_conv_n_layers: 3
taco_enc_conv_kernel_size: 5
taco_enc_rnn_n_layers: 1
taco_enc_dropout: 0.5
taco_dec_channels: 1024
taco_dec_atten_conv_channels: 32
taco_dec_atten_conv_kernel_size: 31
taco_dec_atten_hidden_channels: 128
taco_dec_rnn_n_layers: 2
taco_dec_prenet_hidden_channels: 256
taco_dec_prenet_inner_channels: 256
taco_dec_prenet_n_layers: 2
taco_dec_dropout: 0.1
taco_post_hidden_channels: 512
taco_post_n_layers: 5
taco_post_kernel_size: 5
taco_lip_prenet_hidden_channels: 32
taco_lip_prenet_dropout: 0.5
taco_lip_out_hidden_channels: 256
taco_lip_out_dropout: 0.1
taco_lip_post_hidden_channels: 64
taco_lip_post_n_layers: 5
taco_lip_post_kernel_size: 5
lip_post_dropout: 0.5
taco_vae_hidden_channels: 512
taco_vae_n_conv_layers: 6
taco_vae_n_rnn_layers: 2
taco_vae_z_dim: 32

# avhubert
avhubert_config:
  model_size: 'base'
  load_pretrained_weight: True
  base:
    ckpt_path: '~/av_hubert_data/base_vox_iter5_torch.ckpt'
    resnet_relu_type: 'prelu'
    resnet_weights: 
    audio_feat_dim: 104
    encoder_embed_dim: 768
    dropout_input: 0.1
    dropout_features: 0.1
    modality_fuse: 'concat'
    encoder_layers: 12
    sub_encoder_layers: 0
    dropout: 0.1
    conv_pos: 128
    conv_pos_groups: 16
    encoder_ffn_embed_dim: 3072
    encoder_attention_heads: 12
    attention_dropout: 0.1
    activation_dropout: 0.0
    activation_fn: 'gelu'
    layer_norm_first: True
    encoder_layerdrop: 0.05
    use_soft_prompt: False
    n_prompt_tokens: 10
    use_prompt_block: False
    prompt_block_kernel_size: 3
    prompt_block_se_r: 16
  large:
    ckpt_path: '~/av_hubert_data/large_vox_iter5_torch.ckpt'
    resnet_relu_type: 'prelu'
    resnet_weights: 
    audio_feat_dim: 104
    encoder_embed_dim: 1024
    dropout_input: 0.1
    dropout_features: 0.1
    modality_fuse: 'concat'
    encoder_layers: 24
    sub_encoder_layers: 0
    dropout: 0.1
    conv_pos: 128
    conv_pos_groups: 16
    encoder_ffn_embed_dim: 4096
    encoder_attention_heads: 16
    attention_dropout: 0.1
    activation_dropout: 0.0
    activation_fn: 'gelu'
    layer_norm_first: True
    encoder_layerdrop: 0.05
    use_soft_prompt: False
    n_prompt_tokens: 10
    use_prompt_block: False
    prompt_block_kernel_size: 3
    prompt_block_se_r: 16

# raven
raven_config:
  model_size: 'base'
  load_pretrained_weight: True
  base:
    ckpt_path: '~/raven_data/raven_vox2lrs3_base_video.pth'
    idim: 512
    adim: 512
    aheads: 8
    eunits: 2048
    elayers: 12
    transformer_frontend: conv3d
    transformer_input_layer: vanilla_linear
    dropout_rate: 0.1
    transformer_attn_dropout_rate: 0.1
    transformer_encoder_attn_layer_type: rel_mha
    macaron_style: False
    use_cnn_module: False
    cnn_module_kernel: 31
    zero_triu: False
    a_upsample_ratio: 1
    relu_type: swish
    ddim: 512
    dheads: 8
    dunits: 2048
    dlayers: 6
    lsm_weight: 0.1
    transformer_length_normalized_loss: False
    rel_pos_type: latest
    layerscale: True
    init_values: 0.1
    ff_bn_pre: True
    post_norm: False
    gamma_zero: False
    gamma_init: 0.1
    mask_init_type:
    ctc_type: warpctc
    drop_path: 0.0
    mtlalpha: 0.1
  large:
    ckpt_path: '~/raven_data/raven_vox2lrs3_large_video.pth'
    idim: 512
    adim: 1024
    aheads: 16
    eunits: 4096
    elayers: 24
    transformer_frontend: conv3d
    transformer_input_layer: vanilla_linear
    dropout_rate: 0.1
    transformer_attn_dropout_rate: 0.1
    transformer_encoder_attn_layer_type: rel_mha
    macaron_style: False
    use_cnn_module: False
    cnn_module_kernel: 31
    zero_triu: False
    a_upsample_ratio: 1
    relu_type: swish
    ddim: 1024
    dheads: 16
    dunits: 4096
    dlayers: 9
    lsm_weight: 0.1
    transformer_length_normalized_loss: False
    rel_pos_type: latest
    layerscale: True
    init_values: 0.1
    ff_bn_pre: True
    post_norm: False
    gamma_zero: False
    gamma_init: 0.1
    mask_init_type:
    ctc_type: warpctc
    drop_path: 0.1
    mtlalpha: 0.1

# vatlm
vatlm_config:
  model_size: 'base'
  load_pretrained_weight: True
  base:
    ckpt_path: '~/vatlm_data/pretrain_base_vox2_torch.ckpt'
    cfg:
      label_rate: 25
      modalities: ['video']
      extractor_mode: 'default'
      encoder_layers: 12
      encoder_embed_dim: 768
      encoder_ffn_embed_dim: 3072
      encoder_attention_heads: 12
      activation_fn: "gelu"
      dropout: 0.0
      attention_dropout: 0.0
      activation_dropout: 0.1
      encoder_layerdrop: 0.0
      dropout_input: 0.0
      dropout_features: 0.0
      final_dim: 0
      untie_final_proj: False
      layer_norm_first: False
      conv_feature_layers: "[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2"
      conv_bias: False
      logit_temp: 0.1
      target_glu: False
      feature_grad_mult: 1.0
      mask_length_audio: 10
      mask_prob_audio: 0.65
      mask_length_image: 10
      mask_prob_image: 0.65
      mask_selection: 'static'
      mask_other: 0
      no_mask_overlap: False
      mask_min_space: 1
      mask_channel_length: 64
      mask_channel_prob: 0.5
      mask_channel_selection: 'static'
      mask_channel_other: 0
      no_mask_channel_overlap: False
      mask_channel_min_space: 1
      conv_pos: 128
      conv_pos_groups: 16
      latent_temp: (2, 0.5, 0.999995)
      skip_masked: False
      skip_nomask: False
      resnet_relu_type: 'prelu'
      resnet_weights: 
      sim_type: 'cosine'
      sub_encoder_layers: 0
      audio_feat_dim: 104
      modality_dropout: 0
      audio_dropout: 00
      modality_fuse: 'concat'
      selection_type: 'same_other_seq'
      masking_type: 'input'
      decoder_embed_dim: 768
      decoder_ffn_embed_dim: 3072
      decoder_layers: 6
      decoder_layerdrop: 0.0
      decoder_attention_heads: 4
      decoder_learned_pos: False
      decoder_normalize_before: True
      no_token_positional_embeddings: False
      decoder_dropout: 0.1
      decoder_attention_dropout: 0.0
      decoder_activation_dropout: 0.1
      max_target_positions: 2048
      share_decoder_input_output_embed: True
      no_scale_embedding: True
    task_cfg:
      data: ''
      labels: ["wrd"]
      label_dir: ''
      label_rate: 25
      sample_rate: 16_000
      normalize: True
      enable_padding: False
      max_sample_size: 500
      min_sample_size: 
      max_trim_sample_size: 5000
      single_target: True
      random_crop: False
      pad_audio: True
      pdb: False
      stack_order_audio: 4
      skip_verify: False
      text_sampling_alpha: 0.2
      split_modality_batch: False
      image_aug: True
      image_crop_size: 88
      image_mean: 0.421
      image_std: 0.165
      modalities: ["video","audio"]
      is_s2s: True
      tokenizer_bpe_name: 'sentencepiece'
      tokenizer_bpe_model: 
      noise_wav: 
      noise_prob: 0
      noise_snr: '0'
      noise_num: 1
      fine_tuning: True
      use_supervised_data: True
      sup_data_path: 
      sup_manifest: 
      sample_distributions: '0'
      use_extra_textdata: True
      onlytext_manifest: 
      use_extra_audiodata: True
      onlyaudio_manifest: 
  large:
    ckpt_path: '~/vatlm_data/pretrain_large_vox2_torch.ckpt'
    cfg:
      label_rate: 25
      modalities: ['video']
      extractor_mode: 'default'
      encoder_layers: 24
      encoder_embed_dim: 1024
      encoder_ffn_embed_dim: 4096
      encoder_attention_heads: 16
      activation_fn: "gelu"
      dropout: 0.0
      attention_dropout: 0.0
      activation_dropout: 0.1
      encoder_layerdrop: 0.0
      dropout_input: 0.0
      dropout_features: 0.0
      final_dim: 0
      untie_final_proj: False
      layer_norm_first: False
      conv_feature_layers: "[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2"
      conv_bias: False
      logit_temp: 0.1
      target_glu: False
      feature_grad_mult: 1.0
      mask_length_audio: 10
      mask_prob_audio: 0.65
      mask_length_image: 10
      mask_prob_image: 0.65
      mask_selection: 'static'
      mask_other: 0
      no_mask_overlap: False
      mask_min_space: 1
      mask_channel_length: 64
      mask_channel_prob: 0.5
      mask_channel_selection: 'static'
      mask_channel_other: 0
      no_mask_channel_overlap: False
      mask_channel_min_space: 1
      conv_pos: 128
      conv_pos_groups: 16
      latent_temp: (2, 0.5, 0.999995)
      skip_masked: False
      skip_nomask: False
      resnet_relu_type: 'prelu'
      resnet_weights: 
      sim_type: 'cosine'
      sub_encoder_layers: 0
      audio_feat_dim: 104
      modality_dropout: 0
      audio_dropout: 0.0
      modality_fuse: 'concat'
      selection_type: 'same_other_seq'
      masking_type: 'input'
      decoder_embed_dim: 1024
      decoder_ffn_embed_dim: 4096
      decoder_layers: 9
      decoder_layerdrop: 0.0
      decoder_attention_heads: 8
      decoder_learned_pos: False
      decoder_normalize_before: True
      no_token_positional_embeddings: False
      decoder_dropout: 0.1
      decoder_attention_dropout: 0.0
      decoder_activation_dropout: 0.1
      max_target_positions: 2048
      share_decoder_input_output_embed: True
      no_scale_embedding: True
    task_cfg:
      data: ''
      labels: ["wrd"]
      label_dir: ''
      label_rate: 25
      sample_rate: 16_000
      normalize: True
      enable_padding: False
      max_sample_size: 500
      min_sample_size: 
      max_trim_sample_size: 5000
      single_target: True
      random_crop: False
      pad_audio: True
      pdb: False
      stack_order_audio: 4
      skip_verify: False
      text_sampling_alpha: 0.2
      split_modality_batch: False
      image_aug: True
      image_crop_size: 88
      image_mean: 0.421
      image_std: 0.165
      modalities: ["video"]
      is_s2s: True
      tokenizer_bpe_name: 'sentencepiece'
      tokenizer_bpe_model: 
      noise_wav: 
      noise_prob: 0
      noise_snr: '0'
      noise_num: 1
      fine_tuning: True
      use_supervised_data: True
      sup_data_path: 
      sup_manifest: 
      sample_distributions: '0'
      use_extra_textdata: True
      onlytext_manifest: 
      use_extra_audiodata: True
      onlyaudio_manifest: 