---

name : "lipreading"

# デバッグ
debug : True
debug_data_len : 1000
debug_max_epoch : 200
debug_iter : 0

# checkpointから再開する場合
check_point_start : False
start_ckpt_path : "~/lip2sp_pytorch/check_point/lipreading/lip_st_03/2022:11:05_00-14-21/mspec80_10.ckpt"

# face or lip
face_or_lip : "face_aligned_0_50_gray"

# 学習したモデルのパラメータを保存するディレクトリまでのパス
save_path : "~/lip2sp_pytorch/result/lipreading/train"

# check point path
ckpt_path : "~/lip2sp_pytorch/check_point/lipreading"
ckpt_step : 10

# 口唇動画、音響特徴量ディレクトリまでのパス
lip_pre_loaded_path_train_03_50_gray : "~/dataset/lip/np_files/lip_cropped_0.3_50_gray/train"
lip_pre_loaded_path_val_03_50_gray : "~/dataset/lip/np_files/lip_cropped_0.3_50_gray/val"

lip_pre_loaded_path_train_08_50_gray : "~/dataset/lip/np_files/lip_cropped_0.8_50_gray/train"
lip_pre_loaded_path_val_08_50_gray : "~/dataset/lip/np_files/lip_cropped_0.8_50_gray/val"

face_pre_loaded_path_train_0_50_gray : "~/dataset/lip/np_files/face_aligned_0_50_gray/train"
face_pre_loaded_path_val_0_50_gray : "~/dataset/lip/np_files/face_aligned_0_50_gray/val"

face_pre_loaded_path_train_0_50 : "~/dataset/lip/np_files/face_aligned_0_50/train"
face_pre_loaded_path_val_0_50 : "~/dataset/lip/np_files/face_aligned_0_50/val"

# 使用するコーパス
# corpus : ["ATR", "BASIC5000", "balanced"]
corpus : ["ATR"]

# 使用する話者
speaker : ["F01_kablab"]
use_gc : False

# max_epoch
max_epoch : 600

# data augmentationの有無
# 見た目変換系
use_color_jitter : False
use_blur : False
use_pad : False
use_rotation : False
use_horizontal_flip : False
use_random_crop : False

# 空間領域にランダムマスキング
use_spatial_masking : False
which_spatial_mask : "has"
spatial_divide_factor : 4
n_spatial_mask : 8
mask_length : 24

# 再生速度変換
use_time_augment : False
time_augment_rate : 20    # (100 - rate)から(100 + rate)の範囲で再生速度を変更

# 動画の連続したフレームをある程度まとめてマスキング
use_segment_masking : False
which_seg_mask : "seg_mean"
min_segment_masking_length : 0
max_segment_masking_length : 25

# 音響特徴量に対してのマスキング
use_time_frequency_masking : False
feature_time_masking_length : 50
feature_freq_masking_band : 40

# dataloader
batch_size : 8
num_workers : 8

# dropout
dec_dropout : 0.5
res_dropout : 0.1
rnn_dropout : 0.1
f0_predicter_dropout : 0.5

# optimizer
lr : 0.001
lr_lf : 0.0001
beta_1 : 0.9
beta_2 : 0.999
weight_decay : 1.0e-6

# scheduler
lr_decay_rate : 0.5
multi_lr_decay_step : [200, 400]   # 学習率を変更するepoch
lr_decay_exp : 0.997
use_warmup_scheduler : True

# gradient clipping
max_norm : 3.0

# parameter for scheduled sampling
# min_mixing_prob = 1 : teacher forcing
# min_mixing_probが小さくなるほどサンプルが劣化する(最小0)
exp_factor : 0.98
min_mixing_prob : 0.0

# lossの重みづけ
output_loss_weight : 1.0
dec_output_loss_weight : 1.0
delta_loss_w : 1.0
f0_loss_weight : 1.0
use_weighted_mean : False