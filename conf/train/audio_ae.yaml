---

name : "audio_ae"

# デバッグ
debug : False
debug_data_len : 1000
debug_max_epoch : 200
debug_iter : 3

# checkpointから再開する場合
check_point_start : False
start_ckpt_path : "~/lip2sp_pytorch/check_point/audio_ae/face_cropped_max_size_fps25/2023:08:11_22-14-18/mspec80_1.ckpt"

# audio autoencoder
pretrained_model_path : '~/lip2sp_pytorch/check_point/audio_ae/face_cropped_max_size_fps25/2023:08:13_00-43-47/mspec80_20.ckpt'
load_pretrained_model : False

# 複数言語で事前学習したモデルをfine tuningするかどうか
fine_tuning_pretrained_model_by_external_data : False

# モデルの中で固定するところ
module_is_fixed : ['audio_encoder', 'audio_decoder']

# check_point_startだと、以前の保存用ディレクトリに続けて保存されてしまうので、分けたい時用
check_point_start_separate_save_dir : False
start_ckpt_path_separate_save_dir : "~/lip2sp_pytorch/check_point/audio_ae/face_cropped_max_size_fps25/2023:07:20_02-32-49/mspec80_400.ckpt"

# face or lip
face_or_lip : "face_cropped_max_size_fps25"
use_synth_corpus : False
n_data_used_recorded_and_synth : 20000

# 学習したモデルのパラメータを保存するディレクトリまでのパス
save_path : "~/lip2sp_pytorch/result/audio_ae/train"

# check point path
ckpt_path : "~/lip2sp_pytorch/check_point/audio_ae"
ckpt_step : 1

# 口唇動画、音響特徴量ディレクトリまでのパス
lip_pre_loaded_path_train_03_50_gray : "~/dataset/lip/np_files/lip_cropped_0.3_50_gray/train"
lip_pre_loaded_path_val_03_50_gray : "~/dataset/lip/np_files/lip_cropped_0.3_50_gray/val"
lip_pre_loaded_path_train_08_50_gray : "~/dataset/lip/np_files/lip_cropped_0.8_50_gray/train"
lip_pre_loaded_path_val_08_50_gray : "~/dataset/lip/np_files/lip_cropped_0.8_50_gray/val"
face_pre_loaded_path_train_0_50_gray : "~/dataset/lip/np_files/face_aligned_0_50_gray/train"
face_pre_loaded_path_val_0_50_gray : "~/dataset/lip/np_files/face_aligned_0_50_gray/val"
face_pre_loaded_path_train_0_50 : "~/dataset/lip/np_files/face_aligned_0_50/train"
face_pre_loaded_path_val_0_50 : "~/dataset/lip/np_files/face_aligned_0_50/val"
synth_path_train : "~/dataset/lip/np_files_synth_corpus/face_aligned_0_50_gray/train"
recorded_and_synth_path_train : "~/dataset/lip/np_files_recorded_and_synth/face_aligned_0_50_gray/train"
recorded_and_synth_path_val : "~/dataset/lip/np_files_recorded_and_synth/face_aligned_0_50_gray/val"
face_cropped_max_size_train : "~/dataset/lip/np_files/face_cropped_max_size_0_50_gray/train"
face_cropped_max_size_val : "~/dataset/lip/np_files/face_cropped_max_size_0_50_gray/val"
face_cropped_max_size_fps25_train : "~/dataset/lip/np_files/face_cropped_max_size_fps25_0_25_gray/train"
face_cropped_max_size_fps25_val : "~/dataset/lip/np_files/face_cropped_max_size_fps25_0_25_gray/val"

# 元データ
data_dir : "~/dataset/lip/cropped"
bbox_dir : "~/dataset/lip/bbox"
landmark_dir : "~/dataset/lip/landmark"
# data_dir : "~/dataset/lip/cropped_fps25"
# bbox_dir : "~/dataset/lip/bbox_fps25"
# landmark_dir : "~/dataset/lip/landmark_fps25"
train_df_path : "~/dataset/lip/data_split_csv/train_all.csv"
val_df_path : "~/dataset/lip/data_split_csv/val.csv"

# 外部データの指定
which_external_data : ""

# lrs2
lrs2_train_data_root : "~/lrs2/mvlrs_v1/main"
lrs2_val_data_root : "~/lrs2/mvlrs_v1/main"
lrs2_train_data_bbox_root : "~/lrs2/bbox/main"
lrs2_val_data_bbox_root : "~/lrs2/bbox/main"
lrs2_train_data_landmark_root : "~/lrs2/landmark/main"
lrs2_val_data_landmark_root : "~/lrs2/landmark/main"
lrs2_train_df_path : "~/lrs2/train.txt"
lrs2_val_df_path : "~/lrs2/val.txt"
lrs2_n_train_speaker_used : 200
lrs2_main_npz_path : "~/dataset/lip/np_files/lrs2_main/train"
lrs2_pretrain_npz_path : "~/dataset/lip/np_files/lrs2_pretrain/train"

# lip2wav
lip2wav_npz_path : "~/dataset/lip/np_files/lip2wav/train"
npz_process_speaker_list : []

# jsut corpus
use_jsut_corpus : True
jsut_path_train : "~/dataset/lip/np_files/jsut/train"

# jvs corpus
use_jvs_corpus : True
jvs_path_train : "~/dataset/lip/np_files/jvs/train"

# 使用するコーパス
# corpus : ["ATR", "BASIC5000", "balanced"]
corpus : ["ATR"]
corpus_synth : [
  "ATR", "BASIC5000", "balanced", "COUNTERSUFFIX26", "LOANWORD128", "ONOMATOPEE300", "PRECEDENT130", "TRAVEL1000", 
  "UT-PARAPHRASE", "VOICEACTRESS100", "wiki"
]

# data upsampling
apply_upsampling : True

# 使用する話者
# speaker : ["M04_kablab"]
speaker : ["F01_kablab", "F02_kablab", "M01_kablab", "M04_kablab"]
use_spk_emb : True
finetuning : False
where_spk_emb : "after_res"
adversarial_learning : False

# max_epoch
max_epoch : 30

# テキスト処理
for_tts : False

# data augmentationの有無
# 見た目変換系
use_color_jitter : False
use_blur : False
use_pad : False
use_rotation : False
use_horizontal_flip : True
use_random_crop : True

# 空間領域にランダムマスキング
use_spatial_masking : False
which_spatial_mask : "has"
spatial_divide_factor : 8
n_spatial_mask : 24
mask_length : 24

# 再生速度変換
use_time_augment : False
time_augment_rate : 20    # (100 - rate)から(100 + rate)の範囲で再生速度を変更

# 動画の連続したフレームをある程度まとめてマスキング
use_segment_masking : True
which_seg_mask : "seg_mean"
max_segment_masking_sec : 0.5

# 音響特徴量に対してのマスキング
use_time_frequency_masking : False
feature_time_masking_length : 50
feature_freq_masking_band : 40

# dataloader
batch_size : 16
num_workers : 16

# dropout
dec_dropout : 0.1
res_dropout : 0.1
rnn_dropout : 0.1
lm_enc_dropout : 0.1

# optimizer
lr : 1.0e-4
beta_1 : 0.9
beta_2 : 0.999
weight_decay : 1.0e-6
# beta_2 : 0.98
# weight_decay : 1.0e-2
which_optim : 'adam'
which_scheduler : 'exp'

# scheduler
lr_decay_rate : 0.5
multi_lr_decay_step : [200, 400]   # 学習率を変更するepoch
lr_decay_exp : 0.9
use_warmup_scheduler : False
warmup_t_rate : 0.1
warmup_lr_init : 1.0e-5
warmup_lr_min : 0

# gradient clipping
max_norm : 3.0

# lossの重みづけ
mse_loss_mel_weight : 1.0
mse_loss_enc_feature : 1.0
mse_loss_mel_between_enc : 1.0

# gradient accumulation
iters_to_accumulate : 1

# early stopping
num_wait_epoch_for_early_stopping : 10
use_early_stopping : False