---

name : "nar"

# 乱数固定
random_seed : 42

# デバッグ
debug : True
debug_data_len : 1000
debug_max_epoch : 200
debug_iter : 50

# checkpointから再開する場合
check_point_start : False
start_ckpt_path : "~/lip2sp_pytorch/check_point/nar/face_cropped_max_size_fps25/2023:07:20_02-32-49/mspec80_400.ckpt"

# 複数言語で事前学習したモデルをfine tuningするかどうか
fine_tuning_pretrained_model_by_external_data : False

# 固定するレイヤーを指定
module_is_fixed : ['avhubert_postnet']

# check_point_startだと、以前の保存用ディレクトリに続けて保存されてしまうので、分けたい時用
check_point_start_separate_save_dir : False
start_ckpt_path_separate_save_dir : "~/lip2sp_pytorch/check_point/nar/face_cropped_max_size_fps25/2023:07:20_02-32-49/mspec80_400.ckpt"

# face or lip
face_or_lip : "avhubert_preprocess_fps25_gray"
use_synth_corpus : False
n_data_used_recorded_and_synth : 20000

# 学習したモデルのパラメータを保存するディレクトリまでのパス
save_path : "~/lip2sp_pytorch/result/nar/train"

# check point path
ckpt_path : "~/lip2sp_pytorch/check_point/nar"
ckpt_step : 1

# 口唇動画、音響特徴量ディレクトリまでのパス
avhubert_preprocess_fps25_train : "~/dataset/lip/np_files/avhubert_preprocess_fps25_gray/train"
avhubert_preprocess_fps25_val : "~/dataset/lip/np_files/avhubert_preprocess_fps25_gray/val"

# kablab
kablab:
  audio_dir: '~/dataset/lip/wav'
  avhubert_preprocess_fps25_video_dir: '~/dataset/lip/avhubert_preprocess_fps25'
  df_path: '~/dataset/lip/data_split_csv/kablab.csv'
  emb_dir: '~/dataset/lip/emb'
  text_dir: '~/dataset/lip/utt'

# tcd_timit
tcd_timit:
  use: False
  audio_dir: '~/tcd_timit'
  avhubert_preprocess_fps25_video_dir: '~/tcd_timit_fps25_avhubert_preprocess'
  df_path: '~/dataset/lip/data_split_csv/tcd_timit.csv'
  emb_dir : '~/tcd_timit'
  text_dir: '~/tcd_timit'

# 外部データの指定
which_external_data : ""

# lrs2
lrs2_train_data_root : "~/lrs2/mvlrs_v1/main"
lrs2_val_data_root : "~/lrs2/mvlrs_v1/main"
lrs2_train_data_bbox_root : "~/lrs2/bbox/main"
lrs2_val_data_bbox_root : "~/lrs2/bbox/main"
lrs2_train_data_landmark_root : "~/lrs2/landmark/main"
lrs2_val_data_landmark_root : "~/lrs2/landmark/main"
lrs2_train_df_path : "~/lrs2/train.txt"
lrs2_val_df_path : "~/lrs2/val.txt"
lrs2_n_train_speaker_used : 200
lrs2_main_npz_path : "~/dataset/lip/np_files/lrs2_main/train"
lrs2_pretrain_npz_path : "~/dataset/lip/np_files/lrs2_pretrain/train"

# lip2wav
lip2wav_npz_path : "~/dataset/lip/np_files/lip2wav/train"
npz_process_speaker_list : []

# jsut corpus
use_jsut_corpus : False
jsut_path_train : "~/dataset/lip/np_files/jsut/train"
jsut_path_val : "~/dataset/lip/np_files/jsut/val"

# jvs corpus
jvs:
  use: False
  data_dir: '~/dataset/jvs_ver1'
  df_path: '~/dataset/lip/data_split_csv/jvs.csv'
  path_train: "~/dataset/lip/np_files/jvs/train"
  emb_dir: '~/dataset/jvs_ver1/emb'

# hifi-captain
hifi_captain:
  use: False
  data_dir: '~/dataset/hi-fi-captain/ja-JP'
  df_path: '~/dataset/lip/data_split_csv/hifi_captain.csv'
  feat_mean_var_std_path: '~/dataset/hi-fi-captain/ja-JP/feat_mean_var_std.npz'
  emb_dir: '~/dataset/hi-fi-captain/ja-JP'


# 使用するコーパス
# corpus : ["ATR", "BASIC5000", "balanced"]
corpus : ["ATR"]
corpus_synth : [
  "ATR", "BASIC5000", "balanced", "COUNTERSUFFIX26", "LOANWORD128", "ONOMATOPEE300", "PRECEDENT130", "TRAVEL1000", 
  "UT-PARAPHRASE", "VOICEACTRESS100", "wiki"
]

# data upsampling
apply_upsampling : False

# 使用する話者
speaker : ["F01_kablab", "M01_kablab"]
use_spk_emb : True
finetuning : False
where_spk_emb : "after_res"
adversarial_learning : False

# max_epoch
max_epoch : 50

# テキスト処理
for_tts : False

# data augmentationの有無
# 見た目変換系
use_color_jitter : False
use_blur : False
use_pad : False
use_rotation : False
use_horizontal_flip : True
use_random_crop : True

# 空間領域にランダムマスキング
use_spatial_masking : False
which_spatial_mask : "has"
spatial_divide_factor : 8
n_spatial_mask : 24
mask_length : 24

# 再生速度変換
use_time_augment : False
time_augment_rate : 20    # (100 - rate)から(100 + rate)の範囲で再生速度を変更

# 動画の連続したフレームをある程度まとめてマスキング
use_segment_masking : True
which_seg_mask : "seg_mean"
max_segment_masking_sec : 0.5

# 音響特徴量に対してのマスキング
use_time_frequency_masking : False
feature_time_masking_length : 50
feature_freq_masking_band : 40

# dataloader
batch_size : 2
num_workers : 2
iters_to_accumulate : 16

# dropout
dec_dropout : 0.1
res_dropout : 0.1
rnn_dropout : 0.1
lm_enc_dropout : 0.1

# optimizer
lr : 1.0e-3
beta_1 : 0.9
# beta_2 : 0.999
# weight_decay : 1.0e-6
beta_2 : 0.98
weight_decay : 1.0e-2
which_optim : 'adamw'
which_scheduler : 'warmup'

# scheduler
lr_decay_rate : 0.5
multi_lr_decay_step : [200, 400]   # 学習率を変更するepoch
lr_decay_exp : 0.9
warmup_t_rate : 0.1
warmup_lr_init : 1.0e-5
warmup_lr_min : 0

# gradient clipping
max_norm : 3.0

# lossの重みづけ
mse_weight : 1.0
l1_loss_weight : 1.0
classifier_weight : 0.05
use_weighted_mean : False
loss_disc_weight : 0.01